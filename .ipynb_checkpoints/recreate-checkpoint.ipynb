{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "from keras import metrics\n",
    "\n",
    "from vgg16_avg import VGG16_Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets all images\n",
    "\n",
    "path = '/home/ubuntu/StyleGAN/train/'\n",
    "all_images = glob.glob(path+'*/*'); len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = all_images[1707] #taken from imagenet (is the truck photo)\n",
    "img = Image.open(file)\n",
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sty_dir = '/home/ubuntu/StyleGAN/starry_night.jpg' #style photo\n",
    "style = Image.open(sty_dir).resize(img.size, Image.ANTIALIAS); style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Preprocess and Imagenet Mean subtractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rgb_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)\n",
    "preproc = lambda x : (x - rgb_mean)[:, :, :, ::-1]\n",
    "deproc = lambda x, s : np.clip(x.reshape(s)[:, :, :, ::-1] + rgb_mean, 0, 255)\n",
    "img_arr = preproc(np.expand_dims(np.array(img), 0))\n",
    "style_arr = preproc(np.expand_dims(np.array(style), 0))\n",
    "img_shape = img_arr.shape\n",
    "sty_shape = style_arr.shape\n",
    "img_shape, sty_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = img_arr.shape[1:] #expanding dims for keras purposes (only takes 4D tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16_Avg(include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_output = model.get_layer('block5_conv1').output; cont_output #modify output convolution block to vary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_model = Model(model.input, cont_output)\n",
    "targ = K.variable(cont_model.predict(img_arr)) #equivalent to tf.variable as tf is backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object): #separating loss and gradient values\n",
    "    def __init__(self, func, img_shape): self.func, self.img_shape = func, img_shape\n",
    "        \n",
    "    def loss(self, x):\n",
    "        loss_, self.grad_matrix = self.func([x.reshape(img_shape)])\n",
    "        return loss_.astype(np.float64)\n",
    "    \n",
    "    def grads(self, x): return self.grad_matrix.flatten().astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = K.mean(metrics.mse(cont_output, targ))\n",
    "grads = K.gradients(loss, model.input)\n",
    "fn = K.function([model.input], [loss] + grads)\n",
    "eval_obj = Evaluator(fn, img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prog_path = '/home/ubuntu/StyleGAN/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_content(eval_obj, niter, x):\n",
    "    for i in range(niter):\n",
    "        x, min_val, info = fmin_l_bfgs_b(eval_obj.loss, x.flatten(), fprime=eval_obj.grads, maxfun=20)\n",
    "        x = np.clip(x, -127, 127) \n",
    "        \n",
    "        print('Current loss value:', min_val)\n",
    "        imsave(f'{img_prog_path}res_at_iteration_{i}.png', deproc(x.copy(), img_shape)[0])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_img = lambda shape: np.random.uniform(0, 255, shape) #creating noise as initial input\n",
    "x = rand_img(img_shape)\n",
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 10\n",
    "x = recreate_content(eval_obj, iters, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(img_prog_path+'res_at_iteration_9.png') #Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Recreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arr(array): plt.imshow(deproc(array, array.shape)[0].astype('uint8'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_conv_blocks = 5 #vgg case\n",
    "output_dict = {layer.name : layer.output for layer in model.layers}\n",
    "model_outs = [output_dict['block{}_conv1'.format(o)] for o in range(1, total_conv_blocks + 1)] #all possible conv blocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sty_model = Model(model.inputs, model_outs)\n",
    "targs = [K.variable(o) for o in sty_model.predict(style_arr)] #output of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(orig_mat): #gramian matrix \n",
    "    features = K.batch_flatten(K.permute_dimensions(orig_mat, (2, 0, 1)))\n",
    "    return K.dot(features, K.transpose(features)) / orig_mat.get_shape().num_elements()\n",
    "def style_loss(x, targs): return metrics.mse(gram_matrix(x), gram_matrix(targs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = sum(K.mean(style_loss(l1[0], l2[0])) for l1, l2 in zip(model_outs, targs))\n",
    "grads = K.gradients(loss, model.input)\n",
    "sty_fn = K.function([model.input], [loss] + grads)\n",
    "eval_obj = Evaluator(sty_fn, sty_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_img = lambda shape: np.random.uniform(0, 255, shape)\n",
    "x = rand_img(sty_shape)\n",
    "x = scipy.ndimage.filters.gaussian_filter(x, [0,2,2,0]) #gaussian filters seem to do better than a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
